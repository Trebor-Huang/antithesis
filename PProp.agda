{-# OPTIONS --prop --safe --postfix-projections --overlapping-instances #-}

module PProp where
-- Defines PProp, the central tool for the antithesis translation.
-- The extra "P" may stand for "polarized", "paired", or just
-- "double Prop", pick your favourite.

-- On precedences:
-- - The operators on usual Prop takes a precedence of < 15.
-- - The operators on PProp takes â‰¥ 15.
-- - The operators on proof terms takes â‰¥ 10
infix 0 _â˜¯_
infixr 20 Â¬_
infixr 15 _âŸ¶_
infixl 19 _âŠ—_

open import Agda.Primitive using (Level; lzero; lsuc; _âŠ”_)
open import Agda.Builtin.Equality using (_â‰¡_; refl)
open import Preliminary
private variable
    â„“ â„“â‚€ â„“â‚ â„“â‚‚ â„“â‚ƒ â„“â‚„ â„“â‚… â„“â‚† â„“â‚‡ â„“â‚ˆ â„“' â„“â‚' â„“â‚‚' â„“â‚ƒ' â„“â‚„' â„“â‚…' â„“â‚†' â„“â‚‡' â„“â‚ˆ' : Level

-- A PProp, apart from universe level issues, is simply two propositions.
record PProp â„“ â„“' : Set (lsuc (â„“ âŠ” â„“')) where
    field
        Aff : Prop â„“  -- Thesis
        Ref : Prop â„“' -- Antithesis
open PProp
-- The Aff part denotes "how to affirm this PProp", whereas
-- the Ref part denotes "how to refute this PProp".
-- Of course, simply bundling any two propositions together doesn't
-- really buy us anything. Therefore, we impose a third component
-- in this definition: Aff and Ref must be in conflict. In the spirit
-- of Hegel, we call these three Thesis-Antithesis-Synthesis.

-- The Synthesis part is declared as a typeclass for convenience.
record Syn (P : PProp â„“ â„“') : Prop (â„“ âŠ” â„“') where
    field Chu : Aff P -> Ref P -> âŠ¥
open Syn â¦ƒ...â¦„

-- A pretty taichi symbol for that.
_â˜¯_ : {P : PProp â„“ â„“'} -> â¦ƒ Syn P â¦„ -> Aff P -> Ref P -> âŠ¥
_â˜¯_ = Chu
{-# INLINE _â˜¯_ #-}

-- Before we plunge in the development, let's note our choice of âŠ¥ here.
-- Actually, it isn't necessary to use âŠ¥ for it to work: anything would
-- work here! Such a construction is called Chu- or Dialectica-construction.
-- If we choose âŠ¥, then these two constructions become the same. It also makes
-- a lot of additional complications disappear.

private variable
    P : PProp â„“â‚ â„“â‚‚
    Q : PProp â„“â‚ƒ â„“â‚„
    R : PProp â„“â‚… â„“â‚†
    S : PProp â„“â‚‡ â„“â‚ˆ

-- Now we can start defining simple propositions.
ğ•‹ : PProp lzero lzero
ğ•‹ .Aff = âŠ¤
ğ•‹ .Ref = âŠ¥
instance
    Synğ•‹ : Syn ğ•‹
    Synğ•‹ .Chu _ ()

-- Every Prop can be made into a PProp.
-- This resembles the ! (bang / of course) modality in linear logic.
bang : Prop â„“ -> PProp â„“ â„“
bang P .Aff = P
bang P .Ref = P -> âŠ¥
instance
    SynBang : {P : Prop â„“} -> Syn (bang P)
    SynBang .Chu p pÌ… = pÌ… p

-- Negation amounts to switching the affirmation and refutation part.
Â¬_ : PProp â„“â‚ â„“â‚‚ -> PProp â„“â‚‚ â„“â‚
(Â¬ P) .Aff = P .Ref
(Â¬ P) .Ref = P .Aff

-- Double negation for free!
_ : P â‰¡ Â¬ Â¬ P
_ = refl

-- ... But that comes at a cost. Since Â¬ Â¬ P computes to P,
-- this causes Agda to loop if it were declared as an instance:
SynÂ¬ : (P : PProp â„“â‚ â„“â‚‚) -> â¦ƒ Syn P â¦„ -> Syn (Â¬ P)
SynÂ¬ P .Chu p pÌ… = pÌ… â˜¯ p
-- Therefore it should only be used locally, by declaring the argument
-- P explicitly. The canonical usage:
--   let instance _ = SynÂ¬ P in ...

ğ”½ : PProp lzero lzero
ğ”½ = Â¬ ğ•‹
instance
    Synğ”½ : Syn ğ”½
    Synğ”½ = SynÂ¬ ğ•‹

-- But apart from ğ•‹ and ğ”½, we have more bizarre propositions:
ğ•€ : PProp lzero lzero
ğ•€ .Aff = âŠ¥
ğ•€ .Ref = âŠ¥
instance
    Synğ•€ : Syn ğ•€
    Synğ•€ .Chu () ()
-- This is neither provable nor refutable!

-- This is "the" implication that is the most useful in practice.
_âŸ¶_ : PProp â„“â‚ â„“â‚‚ -> PProp â„“â‚ƒ â„“â‚„ -> PProp (â„“â‚ âŠ” â„“â‚‚ âŠ” â„“â‚ƒ âŠ” â„“â‚„) (â„“â‚ âŠ” â„“â‚„)
(P âŸ¶ Q) .Aff = (Aff P -> Aff Q) âˆ§ (Ref Q -> Ref P)
(P âŸ¶ Q) .Ref = Aff P âˆ§ Ref Q

instance
    Syn*âŸ¶ : â¦ƒ Syn P â¦„ -> Syn (P âŸ¶ Q)
    Syn*âŸ¶ .Chu [ a , b ] [ c , d ] = c â˜¯ b d

    SynâŸ¶* : â¦ƒ Syn Q â¦„ -> Syn (P âŸ¶ Q)
    SynâŸ¶* .Chu [ a , b ] [ c , d ] = a c â˜¯ d
    -- These arn't reported as overlapping instances since _âŸ¶_ is
    -- not a rigid term. Also, since we are working over Prop, these
    -- two instances are considered equal.

-- In category speak, we can make PProp a category, and treat each proof of
-- Aff (P âŸ¶ Q) as an arrow from P to Q. Then _âŸ¶_ should become the
-- "internal hom" of this category.

-- The definition of internal hom says that, given a category with a monoidal
-- product _âŠ _, the internal hom is an operation that curries over it:
--   (P âŠ  Q) âŸ¶ R â‰ƒ P âŸ¶ (Q âŸ¶ R).
-- Here we define the internal hom in terms of the monoidal product, however,
-- in practice (such as here), there is a hom-like concept that comes up first,
-- and then we search for the corresponding monoidal product.

-- If you are familiar with linear algebra, then here's a quick example.
-- Consider the set of linear functions between two vector spaces V -> W. Then
-- these functions themselves form a vector space. We would naturally expect that
-- to be the internal hom. What would be the monoidal product? It turns out to
-- be the tensor product of vector spaces.

-- What is the monoidal product corresponding to this internal hom?
-- Thanks to the Chu construction, we can do this neatly:
_âŠ—_ : PProp â„“â‚ â„“â‚‚ -> PProp â„“â‚ƒ â„“â‚„ -> PProp (â„“â‚ âŠ” â„“â‚ƒ) (â„“â‚ âŠ” â„“â‚‚ âŠ” â„“â‚ƒ âŠ” â„“â‚„)
P âŠ— Q = Â¬ (P âŸ¶ Â¬ Q)

-- ğ”½ acts as the "dualizing object" of _âŸ¶_, i.e. _âŸ¶ ğ”½ is the same as Â¬_.
-- ...

